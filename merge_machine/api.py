#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Feb  6 15:01:16 2017

@author: leo

TODO:
    - Safe file name / not unique per date
    
    - API: List of internal referentials
    - API: List of finished modules for given project / source
    - API: List of loaded sources
    
    - API: Fetch infered parameters
    - API: Fetch logs
    - API: Move implicit load out of API
    
    - API: Error codes / remove error
    
    - API: DOWNLOAD CONFIG and run pipeline
    
    - Use logging module
    
    - Change metadata to use_internal and ref_name to last used or smt. Data to
      use is specified on api call and not read from metadata (unless using last used)
    
    - Protect admin functions
    -
    - ADD LICENSE

    - Gray out next button until all fields are properly filled
    - Do not go to next page if an error occured
    - General error handling
    
    - transform_and_download button
    - Download config
    
    - DOWNLOAD full config
    
    - ADD Metadata to file upload (file name, date of validity)
    - User account
    - Auto train 
    
    - ABSOLUTELY: CHANGE to user context rather than _app_ctx_stack . handle memory issues
    - Allocate memory by user/ by IP?
    
    - TODO: look why I can get 90% or 30% match on same file
    - Study impact of training set size on match rate
    - POSTGRES all this ish
    
    - Choose btw add/select/upload and read/load/get
    
    - Catch exceptions. Never redirect if server error

DEV GUIDELINES:
    - By default the API will use the file with the same name in the last 
      module that was completed. Otherwise, you can specify the module to use file from
    - Suggestion methods shall be prefixed by suggest (ex: suggest_load_params, suggest_missing_values)
    - Suggestion methods shall can be plugged as input as params variable of transformation modules
    - Single file modules shall take as input: (pandas_dataframe, params)
    - Single file modules suggestion modules shall ouput (params, log)
    - Single file modules replacement modules shall ouput (pandas_dataframe, log)
    
    - Multiple file modules shall take as input: (pd_dataframe_1, pd_dataframe_2, params)
    - Multiple file modules suggestion modules shall ouput params, log
    - Multiple file modules merge module shall ouput ???
    
    - Files generated by modules should be in module directory and have names determined at the project level (not API, nor module)
    
    - Do NOT return files, instead, user can fetch file through api
    - If bad params are passed to modules, exceptions are raised, it is the APIs role to transform these exceptions in messages
    - Functions to check parameters should be named check_{variable_or_function} (ex: check_file_role)
    - All securing will be done in the API part
    - Always return {"error": ..., "project_id": ..., "response": ...}

    - All methods to load specific configs should raise an error if the config is not coherent
    - For each module, store user input
    
    - Load all configurations to project variables
    
    - Use _init_project when project_type is a variable in path
    
    - Always include project_type as variable or hardcode
    - Put module name before project_type if it exists for all project_type
    - Put module name after project_type if it exists only for this project_type (only with linker)

NOTES:
    - Pay for persistant storage?

# Transform 
curl -i http://127.0.0.1:5000/transform/ -X POST -F "source=@data/tmp/test_merge.csv" -F "ref=@data/tmp/test_merge_small.csv" -F "request_json=@sample_request.json;type=application/json"

# Upload data
curl -i http://127.0.0.1:5000/download/ -X POST -F "request_json=@sample_download_request.json;type=application/json"

# Download data
curl -i http://127.0.0.1:5000/download/ -X POST -F "request_json=@sample_download_request.json;type=application/json"

# Download metadata
curl -i http://127.0.0.1:5000/metadata/ -X POST -F "request_json=@sample_download_request.json;type=application/json"

USES: /python-memcached

"""

import gc
import os

# Change current path to path of api.py
curdir = os.path.dirname(os.path.realpath(__file__))
os.chdir(curdir)

import flask
from flask import Flask, jsonify, render_template, request, send_file, url_for
from flask_session import Session
from flask_socketio import disconnect, emit, SocketIO
from flask_cors import CORS, cross_origin
from werkzeug.utils import secure_filename

import pandas as pd

from dedupe_linker import format_for_dedupe, load_deduper
from labeller import Labeller, DummyLabeller

from admin import Admin
#from user_project import UserProject
#from referential import Referential

from normalizer import UserNormalizer
from linker import UserLinker


#==============================================================================
# INITIATE APPLICATION
#==============================================================================

# Initiate application
app = Flask(__name__)
cors = CORS(app)
app.config['CORS_HEADERS'] = 'Content-Type'
#app.config['SERVER_NAME'] = '127.0.0.1:5000'
app.config['SESSION_TYPE'] = "memcached"# 'memcached'

Session(app)

app.debug = True
app.config['SECRET_KEY'] = open('secret_key.txt').read()
app.config['MAX_CONTENT_LENGTH'] = 2 * 1024 * 1024 * 1024 # Check that files are not too big (2GB)
          
socketio = SocketIO(app)       

#==============================================================================
# HELPER FUNCTIONS
#==============================================================================
    
def _check_privilege(privilege):
    if privilege not in ['user', 'admin']:
        raise Exception('privilege can be only user or admin')

def _check_project_type(project_type):
    if project_type not in ['normalize', 'link']:
        raise Exception('project type can be only normalize or link')

def _check_file_role(file_role):
    if file_role not in ['ref', 'source']:
        raise Exception('File type should be ref or source')

def _check_request():
    '''Check that input request is valid'''
    pass


def _parse_data_params(proj, data_params, file_role=None):
    '''
    Returns identifiers for data based on project history. Uses `get_last_written`
    to retrieve the last file written given the constraints in data_params
    INPUT:
        - proj: a user project
        - data_params: {'file_role': ..., 'module_name': ..., 'file_name': ...}
        - file_role: Constrain the file role (for use in linking...)
    '''
    if data_params is None:
        module_name = None
        file_name = None
    else:
        file_role = data_params.setdefault('file_role', file_role)
        # Skip processing for internal referentials
        if data_params.setdefault('internal', False):
            raise Exception('Internal data NOT YET IMPLEMENTED')
        
        # Load data from last run (or from user specified)
        file_name = data_params.setdefault('file_name', None)
        module_name = data_params.setdefault('module_name', None)
        
    if any(x is None for x in [file_role, module_name, file_name]):
        (file_role, module_name, file_name) = proj.get_last_written(\
                                        file_role, module_name, file_name)
    return (file_role, module_name, file_name)

def _load_from_params(proj, data_params=None):
    '''Load data to project using the parameters received in request.
    Implicit load is systematic. TODO: Define implicit load
    '''
    (file_role, module_name, file_name) = _parse_data_params(proj, data_params)
    proj.load_data(file_role, module_name, file_name)

def _parse_1file_request():
    # Parse json request
    data_params = None
    module_params = None
    if request.json:
        params = request.json
        assert isinstance(params, dict)
    
        if 'data' in params:
            data_params = params['data']
            
            # Make paths secure
            for key, value in data_params.items():
                data_params[key] = secure_filename(value)
            
        if 'params' in params:
            module_params = params['params']
    
    return data_params, module_params
    
def _parse_linking_request():
    data_params = None
    module_params = None
    if request.json:
        params = request.json
        assert isinstance(params, dict)
    
        if 'data' in params:
            data_params = params['data']
            for file_role in ['ref', 'source']:
                # Make paths secure
                for key, value in data_params[file_role].items():
                    data_params[file_role][key] = secure_filename(value)
                
        if 'params' in params:
            module_params = params['params']
    
    return data_params, module_params    

def _gen_dedupe_variable_definition(col_matches):
    my_variable_definition = []
    for match in col_matches:
        if (len(match['source']) != 1) or (len(match['ref']) != 1):
            raise Exception('Not dealing with multiple columns (1 source, 1 ref only)')
        my_variable_definition.append({"crf": True, "missing_values": True, "field": 
            {"ref": match['ref'][0], "source": match['source'][0]}, "type": "String"})
    return my_variable_definition

def _init_project(project_type, 
                 project_id=None, 
                 create_new=False, 
                 display_name=None, 
                 description=None):
    '''
    Runs the appropriate constructor for Linker or Normalizer projects
    
    DEV NOTE: Use this in api calls that have project_type as a variable
    '''
    _check_project_type(project_type)
    
    if project_type == 'link':
        proj = UserLinker(project_id=project_id, 
                          create_new=create_new, 
                          display_name=display_name, 
                          description=description)
    else:
        proj = UserNormalizer(project_id=project_id, 
                              create_new=create_new, 
                              display_name=display_name, 
                              description=description)
    return proj
            

#==============================================================================
# WEB
#==============================================================================

@app.route('/')
@app.route('/web/', methods=['GET'])
@cross_origin()
def web_index():
    #  /!\ Partial URL. Full URL will depend on user form
    next_url_link = url_for('web_select_link_project') 
    next_url_normalize = url_for('web_select_files', 
                                 project_type='normalize', 
                                 project_id='')
    
    return render_template('index.html',
                       next_url_link=next_url_link, 
                       next_url_normalize=next_url_normalize)

@app.route('/web/link/select_project/', methods=['GET'])
@cross_origin()
def web_select_link_project():
    next_url_partial = url_for('web_select_files', project_type='link', project_id='')
    new_link_project_api_url = url_for('new_project', project_type='link')
    delete_project_api_url_partial=url_for('delete_project', project_type='link', project_id='')
    exists_url_partial=url_for('project_exists', project_type='link', project_id='')
    
    admin = Admin()
    list_of_projects = admin.list_projects()
    
    return render_template('select_link_project.html',
                           list_of_projects = list_of_projects,
                           
                           next_url_partial=next_url_partial,
                           new_link_project_api_url=new_link_project_api_url, 
                           delete_project_api_url_partial=delete_project_api_url_partial,
                           exists_url_partial=exists_url_partial)
    

# @app.route('/web/<privilege>/select_files/', methods=['GET'])
@app.route('/web/select_files/<project_type>/<project_id>', methods=['GET'])
@cross_origin()
def web_select_files(project_type, project_id=''):
    '''View to create or join 1 or 2 Normalization projects (1 for norm, 2 for link)'''
    MAX_FILE_SIZE = 1048576
    
    if project_type == 'normalize':
        next_url = None
        next_url_partial = url_for('web_mvs', project_type='normalize') # Missing project_id and file_name
    else:
        next_url = url_for('web_mvs', project_type='link',
                           project_id=project_id, var='source')    
        next_url_partial = None
        
    new_project_api_url = url_for('new_project', project_type=project_type)
    delete_normalize_project_api_url_partial=url_for('delete_project', 'normalize', '')
    delete_file_api_url=None
    
    # Generate Next URLs
    
    # Do what you fina do
    proj = _init_project(project_id=project_id)
    all_csvs = proj._list_files(extensions=['.csv'])
    
    admin = Admin()
    all_internal_refs = admin.list_referentials() # TODO: take care of this

    admin = admin.Admin()
    list_of_projects = user.list_projects()

    # TODO: If you have link, also add files to current 
    
    return render_template('select_files.html', 
                           project_id=project_id,
                           #previous_sources=all_csvs.get('source', []),
                           #previous_references=all_csvs.get('ref', []),
                           #internal_references=all_internal_refs,
                           new_project_api_url=new_project_api_url,
                           delete_normalize_project_api_url_partial = delete_normalize_project_api_url_partial,
                           
                           upload_source_api_url=url_for('upload', project_id=project_id, file_role='source'),
                           upload_ref_api_url=url_for('upload', project_id=project_id, file_role='ref'),
                           select_file_api_url=url_for('select_file', project_id=project_id),
                           next_url=next_url,
                           next_url_partial=next_url_partial,
                           MAX_FILE_SIZE=MAX_FILE_SIZE)


#def _next_url(project_type=None, project_id=None, var=None):
#    # Order if project_type is normalise
#    NORM_ORDER = {'web_index': url_for('web_select_files'),
#                  'web_select_files': url_for('web_mvs'),
#                  'web_mvs': url_for('web_index')
#                  }
#    
#    # Order if project type is link
#    LINK_ORDER = {
#                  'web_index': url_for('web_select_files'),
#                  'web_select_files': url_for('web_mvs'), 
#                  'web_mvs': url_for('web_match_columns'),
#                  'web_match_columns': url_for('web_dedupe'),
#                  'web_dedupe': url_for('web_select_return'),
#                  'web_select_return': url_for('web_download'),
#                  'web_download': url_for('web_index')
#                  }


# order:
# var can be: either: file_name (normalize) or ref or sources
@app.route('/web/missing_values/normalize/<project_id>/<file_name>', methods=['GET'])
@cross_origin()
def web_mvs_normalize(project_id, file_name):
    next_url = url_for('web_download_normalize', 
                       project_id=project_id, 
                       file_name=file_name)    
    return _web_mvs_normalize(project_id, file_name, next_url)
    
@app.route('/web/missing_values/link/<project_id>/<file_role>/', methods=['GET'])
@cross_origin()   
def web_mvs_link(project_id, file_role):
    _check_file_role(file_role)
    
    proj = UserNormalizer(project_id, create_new=False)
    normalize_project_id = proj['metadata']['current'][file_role]['project_id']
    normalize_file_name = proj['metadata']['current'][file_role]['file_name']
    
    if file_role == 'source':
        next_url = url_for('web_mvs_link', project_id=project_id, file_role='ref')
    else:
        next_url = url_for('web_match_columns', project_id=project_id)
    return _web_mvs_normalize(normalize_project_id, normalize_file_name, next_url)


def _web_mvs_normalize(project_id, file_name, next_url):
    NUM_ROWS_TO_DISPLAY = 30
    NUM_PER_MISSING_VAL_TO_DISPLAY = 4          
    # TODO: add click directly on cells with missing values
    
    # proj_norm = init_normalizer_project(project_type=, project_id=project_id)
    
    # Act on last file 
    proj = UserNormalizer()
    (module_name, file_name) = proj.get_last_written(None, file_name, before_module='replace_mvs') 
    
    # Read config or perform inference for project
    proj.load_data(module_name, file_name)
    mvs_config = proj.read_config_data('replace_mvs', 'config.json')
    if not mvs_config:
        # Infer missing values + save
        mvs_config = proj.infer('infer_mvs', params=None)
    
    # Generate sample to display 
    paths = {''}
    sample_params = {
                    'num_rows_to_display': NUM_ROWS_TO_DISPLAY,
                    'num_per_missing_val_to_display': NUM_PER_MISSING_VAL_TO_DISPLAY,
                    'drop_duplicates': True
                     }
    sample = proj.get_sample('sample_mvs', paths, mvs_config, sample_params)
    
    # Format infered_mvs for display in web app
    formated_infered_mvs = dict()
    formated_infered_mvs['columns'] = {col:[mv['val'] for mv in mvs] \
                    for col, mvs in mvs_config['mvs_dict']['columns'].items()}
    formated_infered_mvs['all'] = [mv['val'] for mv in mvs_config['mvs_dict']['all']]
    
    data_params = {'module_name': module_name, 'file_name': file_name}

    return render_template('missing_values.html',
                           project_id=project_id, 
                           formated_infered_mvs=formated_infered_mvs,
                           index=list(sample[0].keys()),
                           sample=sample,
                           
                           data_params=data_params,
                           add_config_api_url=url_for('upload_config', 
                                                      project_id=project_id, 
                                                      module_name='replace_mvs'),
                           recode_missing_values_api_url=url_for('replace_mvs', 
                                                      project_id=project_id),
                           next_url=next_url)


@app.route('/web/link/match_columns/<project_id>/', methods=['GET'])
@cross_origin()
def web_match_columns(project_id):
    ROWS_TO_DISPLAY = range(3)
    
    proj = UserLinker(project_id)
    
    # 
    sample_params = {'sample_ilocs':ROWS_TO_DISPLAY}
    
    # Load source and regsample
    samples = dict()
    for file_role in ['ref', 'source']:
        proj.load_project_to_merge(file_role)
        (_, file_name) = proj.__dict__[file_role].get_last_written(module_name=None, 
                                                      file_name=None, 
                                                      before_module='dedupe_linker')
        proj.__dict__[file_role].load_data('INIT', file_name, nrows=max(ROWS_TO_DISPLAY))
        samples[file_role] = proj.__dict__[file_role].get_sample(None, None, sample_params)
        proj.__dict__[file_role].clear_memory()

    
    # Check valid onfirm valid columns for 
    def config_is_coherent(config, source_sample, ref_sample):
        do_break = False
        for pair in config:
            for col in pair['source']:
                if col not in source_sample[0]:
                    do_break = True
                    break
            for col in pair['ref']:
                if col not in ref_sample[0]:
                    do_break = True
                    break     
            if do_break:
                config = []
                break
        
        return config != []

    # Load previous config
    config = proj.read_col_matches()
    config = config * config_is_coherent(config, samples['source'], samples['ref'])                    
    
    return render_template('match_columns.html',
                           config=config,
                           
                           source_index=list(samples['source'][0].keys()),
                           ref_index=list(samples['ref'][0].keys()),
                           
                           source_sample=samples['source'],
                           ref_sample=samples['ref'],
                                                      
                           add_column_matches_api_url=url_for('add_column_matches', project_id=project_id),
                           next_url=url_for('web_dedupe', project_id=project_id))

    
@socketio.on('answer', namespace='/')
def web_get_answer(user_input):
    # TODO: avoid multiple click (front)
    # TODO: add safeguards  if not enough train (front)
    message = ''
    #message = 'Expect to have about 50% of good proposals in this phase. The more you label, the better...'
    if 'labeller' not in dir(flask._app_ctx_stack):
        emit('redirect', {'url': url_for('web_download', project_id=flask._app_ctx_stack.project_id)})
        disconnect
    else:
        if flask._app_ctx_stack.labeller.answer_is_valid(user_input):
            flask._app_ctx_stack.labeller.parse_valid_answer(user_input)
            if flask._app_ctx_stack.labeller.finished:
                print('Writing train')
                flask._app_ctx_stack.labeller.write_training(flask._app_ctx_stack.paths['train'])
                print('Wrote train')
    
                # TODO: Do dedupe
                next_url = url_for('web_select_return', project_id=flask._app_ctx_stack.project_id, file_role='ref')
                emit('redirect', {'url': next_url})
            else:
                flask._app_ctx_stack.labeller.new_label()
        else:
            message = 'Sent an invalid answer'
        emit('message', flask._app_ctx_stack.labeller.to_emit(message=message))
    

@socketio.on('skip', namespace='/terminate')
def web_terminate_labeller_load():
    pass


@socketio.on('load_labeller', namespace='/')
def load_labeller():
    '''Loads labeller. Necessary to have a separate call to preload page'''    
    # assert flask.session.project_id == project_id   
    def load_dis_labeller():

        print('Got here')
        
        project_id = flask._app_ctx_stack.project_id
        proj = _init_project(privilege='user', project_id=project_id)
        flask._app_ctx_stack.proj = proj
        
        # TODO: Add extra config page
        # TODO: move this to user_project
    
        col_matches = proj.read_col_matches()
        
        # Generate variable definition for dedupe
    
        my_variable_definition = _gen_dedupe_variable_definition(col_matches)
        
        paths = proj.gen_paths_dedupe()  
        print('XXXXXXXXX', paths, 'XXXXXXXXXXXXXXXXXX')
        flask._app_ctx_stack.paths = paths
        
        # Put to dedupe input format
        print('loading ref')
        ref = pd.read_csv(paths['ref'], encoding='utf-8', dtype=str)
        data_ref = format_for_dedupe(ref, my_variable_definition, 'ref') 
        del ref # To save memory
        gc.collect()
        print('loaded_ref')
        
        # Put to dedupe input format
        print('loading source')
        source = pd.read_csv(paths['source'], encoding='utf-8', dtype=str)
        data_source = format_for_dedupe(source, my_variable_definition, 'source')
        del source
        gc.collect()
        print('loaded_source')
        
        #==========================================================================
        # Should really start here
        #==========================================================================
        print('yo')
        deduper = load_deduper(data_ref, data_source, my_variable_definition)
        print('lo')
        flask._app_ctx_stack.labeller = Labeller(deduper, 
                                                 training_path=paths['train'], 
                                                 use_previous=True)
        flask._app_ctx_stack.labeller.new_label()   
        
        print('got there')
        emit('message', flask._app_ctx_stack.labeller.to_emit(message=''))
    load_dis_labeller()
    # socketio.start_background_task(load_dis_labeller)


@app.route('/web/link/dedupe_linker/<project_id>/', methods=['GET'])
@cross_origin()    
def web_dedupe(project_id):
    '''Labelling / training and matching using dedupe'''
    
    # Set project ID in session
    flask.session.project_id = project_id
    flask._app_ctx_stack.project_id = project_id
    
    # TODO: deal with duplicate with load_labeller 
    proj = UserLinker(project_id)
    paths = proj.gen_paths_dedupe()  
    
    dummy_labeller = DummyLabeller(paths, use_previous=True)
    
    # next_url = url_for('web_dedupe', project_id='{{ project_id }}')
    
    return render_template('dedupe_training.html', 
                           **dummy_labeller.to_emit(''))
    #return render_template('dedupe_training.html', **DUMMY_EMIT)


@app.route('/web/select_return/<project_id>/<project_id>', methods=['GET'])
@cross_origin()
def web_select_return(project_id):
    '''
    Configurate file to return for ref and source in same page as well as columns
    that are supposed to match to test results (ex: Siren, SIRENE)
    '''
    # TODO: default to matching columns
    
    ROWS_TO_DISPLAY = range(3)
    
    proj = UserLinker(project_id)
    
    samples = dict()
    selected_columns_to_return = dict()

    for file_role in ['source', 'ref']:
        # Load sample
        data = proj.metadata['current'][file_role]
        
        proj.load_project_to_merge(file_role)
        (module_name, file_name) = proj.__dict__[file_role].get_last_written(None, 
                                                    data['file_name'], 
                                                    before_module='dedupe_linker')
        proj.__dict__[file_role].load_data(module_name, file_name, nrows=max(ROWS_TO_DISPLAY))
        samples[file_role] = proj.get_sample(None, None, {'sample_ilocs':ROWS_TO_DISPLAY})
        
        selected_columns_to_return[file_role] = proj.read_cols_to_return(file_role) 
    
    column_matches = proj.read_col_certain_matches()
    
    indexes = dict()
    indexes['source'] = list(samples['source'][0].keys())
    indexes['ref'] = list(samples['ref'][0].keys())
    
    select_return_api_urls = dict()
    select_return_api_urls['source'] = url_for('add_columns_to_return', 
                                          project_id=project_id, file_role='source')
    select_return_api_urls['ref'] = url_for('add_columns_to_return', 
                                          project_id=project_id, file_role='ref')
    
    next_url = url_for('web_download', project_id=project_id)
    return render_template('select_return.html', 
                           indexes=indexes,                           
                           samples=samples,
                           selected_columns_to_return=selected_columns_to_return,    
                           column_matches=column_matches,
                                                              
                           add_column_certain_matches_api_url=url_for(\
                                        'add_column_certain_matches', project_id=project_id),                          

                           select_return_api_urls=select_return_api_urls,
                           next_url=next_url)
    

@app.route('/web/download/<project_type>/<project_id>/', methods=['GET'])
@cross_origin()
def web_download(project_id):    
    
    proj = _init_project(privilege='user', project_id=project_id)
    
    res_file_name = 'm3_result.csv'
    
    file_path = proj.path_to('link', 
                             'dedupe_linker', 
                             res_file_name
                             )    
    
    if False or (not os.path.isfile(file_path)):        
        paths = proj.gen_paths_dedupe()
        
        col_matches = proj.read_col_matches()
        my_variable_definition = _gen_dedupe_variable_definition(col_matches)
        
        module_params = {
                        'variable_definition': my_variable_definition,
                        'selected_columns_from_source': None,
                        'selected_columns_from_ref': None
                        }  
        
        # TODO: This should probably be moved
        print('Performing deduplication')    
        
        # Perform linking
        proj.linker('dedupe_linker', paths, module_params)
    
        print('Writing data')
        # Write transformations and log
        proj.write_data()    
        proj.write_log_buffer(True)
        
        file_path = proj.path_to(proj.mem_data_info['file_role'], 
                                 proj.mem_data_info['module_name'], 
                                 proj.mem_data_info['file_name'])
        print('Wrote data to: ', file_path)

    # Identify rows to display
    proj.load_data('link', 'dedupe_linker', res_file_name)  

    certain_col_matches = proj.read_col_certain_matches()
    use_lower = True
    metrics = proj.infer('results_analysis', {'col_matches': certain_col_matches, 'lower':use_lower})

    # Choose the columns to display # TODO: Absolutely move this
    col_matches = proj.read_col_matches() # TODO: API this
    suffixes = ('_x', '_y')
    cols_to_display_match = []
    
    #    source_cols = list(set(col for match in col_matches for col in match['source']))
    #    ref_cols = list(set([col for match in col_matches for col in match['ref']] \
    #                                + proj.read_cols_to_return('ref')))

    # TODO: fix for multiple selects of same column
    cols_to_display_match = []
    for col in [_col for match in col_matches for _col in match['source'] + match['ref']]: #\
                #+ proj.read_cols_to_return('ref'):
        if col in cols_to_display_match:
            cols_to_display_match.remove(col)
            cols_to_display_match.append(col + suffixes[0])
            cols_to_display_match.append(col + suffixes[1])
        else:
            cols_to_display_match.append(col)
            
    cols_to_display_match.append('__CONFIDENCE')
    print(cols_to_display_match)
        

    # Choose the columns to display for single source and single ref 
    # TODO: Absolutely change this
    cols_to_display_source = []
    for match in col_matches:
        for col in match['source']:
            if col in cols_to_display_source:
                cols_to_display_source.remove(col)
            else:
                cols_to_display_source.append(col)

    cols_to_display_ref = []
    for match in col_matches:
        for col in match['ref']:
            if col in cols_to_display_ref:
                cols_to_display_ref.remove(col)
            else:
                cols_to_display_ref.append(col)


    # Choose rows to display # TODO: Absolutely move this
    NUM_ROWS_TO_DISPLAY = 1000
    rows_to_display = [0] + list(proj.mem_data.index[proj.mem_data.__CONFIDENCE.notnull()] + 1)
    rows_to_display = rows_to_display[:NUM_ROWS_TO_DISPLAY + 1]
    
    # Generate display sample
    match_sample = proj.get_sample('link', 'dedupe_linker', res_file_name,
                                row_idxs=rows_to_display, columns=cols_to_display_match)

    
    if certain_col_matches:
        sel = proj.mem_data.__CONFIDENCE.notnull()
        if use_lower:
            sel = sel & (proj.mem_data[certain_col_matches['source']].str.lower() \
                         != proj.mem_data[certain_col_matches['ref']].str.lower())
        else:
            sel = sel & (proj.mem_data[certain_col_matches['source']] \
                         != proj.mem_data[certain_col_matches['ref']])
        rows_to_display_error = [0] + list(proj.mem_data.index[sel] + 1)
        rows_to_display_error = rows_to_display_error[:NUM_ROWS_TO_DISPLAY + 1]
        
        match_error_samples = proj.get_sample('link', 'dedupe_linker', res_file_name,
                                    row_idxs=rows_to_display_error, columns=cols_to_display_match)
    else:
        match_error_samples = []
    
    source_sample = proj.get_sample('source', 'INIT', proj.metadata['current']['source']['file_name'],
                                row_idxs=rows_to_display, columns=cols_to_display_source)
    #ref_sample = proj.get_sample('ref', 'INIT', proj.metadata['current']['ref']['file_name'],
    #                            row_idxs=rows_to_display, columns=cols_to_display_ref)

    return render_template('last_page.html', 
                           project_id=project_id,
                           
                           match_index=cols_to_display_match,
                           match_sample=match_sample,
                           match_error_samples=match_error_samples,                           
                           
                           source_index=cols_to_display_source,
                           source_sample=source_sample,
                           ref_index=cols_to_display_ref,
                           # ref_sample=ref_sample,  
                           metrics=metrics,
                           download_api_url=url_for('download', 
                                    privilege='user', project_id=project_id))



#==============================================================================
# API
#==============================================================================

@app.route('/api/new/<project_type>', methods=['GET', 'POST'])
def new_project(project_type):
    _check_project_type(project_type)
    
    # TODO: include internal in form somewhere
    description = request.json.get('description', '')
    display_name = request.json.get('display_name', '')
    internal = request.json.get('internal', False)
    
    if internal and (not description):
        raise Exception('Internal referentials should have a description')

    if project_type == 'normalizer':
        proj = UserNormalizer(create_new=True, description=description, display_name=display_name)
    else:
        proj = UserLinker(create_new=True, description=description, display_name=display_name)

    return jsonify(error=False, 
                   project_id=proj.project_id)

@app.route('/api/delete/<project_type>/<project_id>', methods=['GET'])
def delete_project(project_type, project_id):
    _check_project_type(project_type)
    if project_type == 'normalizer':
        proj = UserNormalizer(project_id=project_id)
    else:
        proj = UserLinker(project_id=project_id)
    proj.delete_project()
    return jsonify(error=False)
    


@app.route('/api/metadata/<project_type>/<project_id>', methods=['GET', 'POST'])
@cross_origin()
def metadata(project_id):
    '''Fetch metadata for project ID'''
    proj = _init_project(project_id=project_id)
    resp = jsonify(error=False,
                   metadata=proj.metadata, 
                   project_id=proj.project_id)
    return resp


@app.route('/api/download/<project_type>/<project_id>', methods=['GET', 'POST'])
@cross_origin()
def download(project_id):
    '''
    Download file from project.
    
    If just project_id: return last modified file
    If variables are specified, return the last file modified with specific variables
    
    '''
    project_id = secure_filename(project_id)

    proj = _init_project(privilege='user', project_id=project_id)
    data_params, _ = _parse_1file_request()
    
    if data_params is None:
        data_params = {}
        
    file_role = data_params.get('file_role', None)
    module_name = data_params.get('module_name', None)
    file_name = data_params.get('file_name', None)
    
    if file_role is not None:
        file_role = secure_filename(file_role)
    if module_name is not None:
        module_name = secure_filename(module_name)
    if file_name is not None:
        file_name = secure_filename(file_name)
        
    (file_role, module_name, file_name) = proj.get_last_written(file_role, module_name, file_name)
        
    if module_name == 'INIT':
        return jsonify(error=True,
               message='No changes were made since upload. Download is not \
                       permitted. Please do not use this service for storage')
    
    file_path = proj.path_to(file_role, module_name, file_name)
    return send_file(file_path, as_attachment=True, attachment_filename='m3_merged.csv')


@app.route('/api/link/select_file/<project_id>', methods=['POST'])
def select_file(project_id):
    '''send {file_role: "source", file_name: "XXX", internal: False}'''
    proj = _init_project(project_id=project_id)
    params = request.json
    proj.select_file(params['file_role'], params.get('file_name', None), \
                     params['internal'], params.get('project_id', project_id))

    return jsonify(error=False)
 
    
@app.route('/api/exists/<project_type>/<project_id>', methods=['GET'])
@cross_origin()
def project_exists(project_type, project_id):
    '''Check if project exists'''
    try:
        _init_project(project_type=project_type, project_id=project_id)
        return jsonify(error=False, exists=True)
    except: 
    
        return jsonify(error=False, exists=False)
    

@app.route('/api/normalize/upload/<project_id>', methods=['POST'])
@cross_origin()
def upload(project_id):
    '''
    Uploads source and reference files to project either passed as variable or
    loaded from request parameters
    '''
    # Load project
    proj = UserNormalizer(project_id=project_id) 
    
    # Upload data
    if 'source' in request.files: # REMOVE "source"; replace by smt
        file = request.files['source']
        if file:
            proj.upload_init_data(file.stream, file.filename)
        else:
            raise Exception('Empty file')
    
    return jsonify(error=False,
               metadata=proj.metadata,
               project_id=proj.project_id)


@app.route('/api/<module_name>/upload_config/<project_type>/<project_id>/', methods=['POST'])
@cross_origin()
def upload_config(module_name, project_id):
    # TODO: do not expose ?
    proj = _init_project(project_id=project_id)    
    paths = request.json['data']
    params = request.json['params']
    proj.upload_config_data(params, paths['file_role'], paths['module_name'], paths['file_name'])
    return jsonify(error=False)


@app.route('/api/link/add_column_matches/<project_id>/', methods=['POST'])
@cross_origin()
def add_column_matches(project_id):
    column_matches = request.json
    proj = _init_project(privilege='user', project_id=project_id)
    proj.add_col_matches(column_matches)
    return jsonify(error=False)
    

@app.route('/api/link/add_column_certain_matches/<project_id>/', methods=['POST'])
@cross_origin()
def add_column_certain_matches(project_id):
    column_matches = request.json
    proj = _init_project(privilege='user', project_id=project_id)
    proj.add_col_certain_matches(column_matches)
    return jsonify(error=False)

@app.route('/api/link/add_columns_to_return/<project_id>/<file_role>/', methods=['POST'])
@cross_origin()
def add_columns_to_return(project_id, file_role):
    columns_to_return = request.json
    proj = _init_project(privilege='user', project_id=project_id)
    proj.add_cols_to_return(file_role, columns_to_return)    
    return jsonify(error=False)

#==============================================================================
# MODULES
#==============================================================================

@app.route('/api/modules/', methods=['GET', 'POST'])
@cross_origin()
def list_modules():
    '''List available modules'''
    return jsonify(error=True,
                   message='This should list the available modules') #TODO: <--


@app.route('/api/modules/infer_mvs/<project_id>/', methods=['GET', 'POST'])
@cross_origin()
def infer_mvs(project_id):
    '''Runs the infer_mvs module'''
    proj = _init_project(project_id=project_id)
    data_params, module_params = _parse_1file_request()    
    
    load_from_params(proj, data_params)
    
    result = proj.infer('infer_mvs', module_params)
        
    # Write log
    proj.write_log_buffer(False)
    
    return jsonify(error=False,
                   response=result)
    
    
@app.route('/api/modules/replace_mvs/<project_id>/', methods=['POST'])
@cross_origin()
def replace_mvs(project_id):
    '''Runs the mvs replacement module'''
    proj = _init_project(project_id=project_id)
    data_params, module_params = parse_1file_request()
    
    load_from_params(proj, data_params)
    proj.transform('replace_mvs', module_params)
    # Write transformations and log
    proj.write_data()    
    proj.write_log_buffer(True)
    
    return jsonify(error=False)


@app.route('/api/link/dedupe_linker/<project_id>/', methods=['POST'])
@cross_origin()
def linker(project_id):
    '''
    Runs deduper module. Contrary to other modules, linker modules, take
    paths as input (in addition to module parameters)
    
    {
    'data': {'source': {},  
            'ref': {}}
    'params': {'variable_definition': {...},
               'columns_to_keep': [...]}
    }
    
    '''
    proj = _init_project(privilege='user', project_id=project_id)
    data_params, module_params = _parse_linking_request()
    
    # Set paths
    (file_role, module_name, file_name) = _parse_data_params(proj, data_params.get('source', None), file_role='source')
    source_path = proj.path_to(file_role='source', module_name=module_name, file_name=file_name)

    (file_role, module_name, file_name) = _parse_data_params(proj, data_params.get('ref', None), file_role='ref')
    ref_path = proj.path_to(file_role='ref', module_name=module_name, file_name=file_name)
    
    paths = {'ref': ref_path, 'source': source_path}
    
    # Perform linking
    proj.linker('dedupe_linker', paths, module_params)

    # Write transformations and log
    proj.write_data()    
    proj.write_log_buffer(True)

    return jsonify(error=False)    
    

#==============================================================================
    # Admin
#==============================================================================

@app.route('/api/list_normalize_projects/', methods=['GET', 'POST'])
@cross_origin()
def list_normalize_projects(user_id=None):
    '''Lists all project id_s'''
    raise Exception('Wrong implementation')
    
    if user_id is not None:
        raise NotImplementedError
    
    admin = Admin()
    list_of_projects = admin.list_projects()
    return jsonify(error=False,
                   response=list_of_projects)

@app.route('/api/list_link_projects/', methods=['GET', 'POST'])
@cross_origin()
def list_link_projects(user_id=None):
    '''Lists all project id_s'''
    raise Exception('Wrong implementation')
    
    if user_id is not None:
        raise NotImplementedError    

    admin = Admin()
    list_of_projects = admin.list_projects()
    return jsonify(error=False,
                   response=list_of_projects)


@app.route('/api/list_referentials/', methods=['GET', 'POST'])
@cross_origin()
def list_referentials():
    '''Lists all internal referentials'''
    admin = Admin()
    list_of_projects = admin.list_referentials()
    return jsonify(error=False,
                   response=list_of_projects)


if __name__ == '__main__':
    socketio.run(app, host='0.0.0.0', port=5000, debug=True)
